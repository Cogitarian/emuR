---
title: "An Introduction to the emuR package"
subtitle: "The Main Package of the EMU Speech Database Management System"
affiliation: "Institute of Phonetics and Speech Processing (LMU Munich)"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: vignettes.bib
vignette: >
  %\VignetteIndexEntry{emuR introduction}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

# WARNING: DOCUMENT STILL BEING WRITTEN!

# Introduction

This document is meant as an introduction to the `emuR` package and is meant to provide an overview of what the package is capable of and how it interacts with the other components of the EMU Speech Database Management System (EMU\_SDMS). It is by no means a definite guide to the EMU\_SDMS but rather tries to give an outline of what it is like working with and analyzing speech databases in the EMU\_SDMS by walking you through a few typical use cases.

The `emuR` package can be viewed as the main component of the EMU\_SDMS as it acts as the central instance that is able to interact with every component of the system. It takes care of database managing duties by being able to interact with a speech database that is stored in the `emuDB` format (see `emuDB` vignette for further details). Further, it has easy to understand and learn yet expressive and powerful querying mechanics, that allow the user to easily query the annotation structures of the database (see `EQL` vignette for further details). Lastly it provides easy data extraction capabilities that extracts data which corresponds to the result of a query.

If a database in the `emuDB` format is present the typical work-flow in `emuR` is usually something like this:

1. Load database into current R session - `load\_emuDB`
2. Database annotation / visual inspection - `serve` and connect the EMU-webApp to the local server
3. Query database - `query` (sometimes followed by `requery_hier` or `requery_seq`)
4. Get trackdata (e.g. formant values) for the result of a query - `get_trackdata`
5. Data preparation
6. Visual data inspection
7. Further analysis and statistical processing

# Converting existing databases

As most people that are starting to use the EMU\_SDMS will probably already have some form of annotated data, we will initially show how you can easily convert this existing data to the `emuDB` format (for a guide on how to create an `emuDB` from scratch and for information about this format see the `emuDB` vignette).

## legacy EMU databases

For people transitioning to `emuR` from the legacy EMU system, `emuR` provides a function for converting existing legacyEmuDBs to the new `emuDB` format. Here is an example of how to use this function:


```{r results='hide', message=FALSE, warning=FALSE}
# load the package
library(emuR)

# create demo data in folder provided by the tempdir() function
create_emuRdemoData(dir = tempdir())

# get the path to a .tpl file of a legacyEmuDB that is part of the demo data
tplPath = file.path(tempdir(), "emuR_demoData", "legacy_ae", "ae.tpl")

# convert this legacyEmuDB to the emuDB format
convert_legacyEmuDB_to_emuDB(emuTplPath = tplPath, targetDir = tempdir())
```

This will create a new `emuDB` in a temporary folder that is provided by the `R` function `tempdir()` containing all the information specified in the `.tpl` file. The name of the new `emuDB` is the same as the basename of the `.tpl` file from which it was generated. In other words, if the template file of your legacyEmuDB has the path `A` and the directory to which the converted database is to be written has the path `B`, then  `convert_legacyEmuDB_to_emuDB("A", targetdir = "B")` will perform the conversion.


```{r}
# remove the newly generated emuDB as we will not be needing it 
# throughout the rest of this vignette
unlink(file.path(tempdir(), "ae"), recursive = T)
```

## TextGrid collections

A further function provided is the `convert_TextGridCollection_to_emuDB()` function. This function converts an existing `.TextGrid` & `.wav` file collection to the `emuDB` format. In order to pair the correct files together the `.TextGrid` files as well as the `.wav` files must have the same name (i.e. file name without extension). A further restriction is that the tiers contained within all the `.TextGrid` files have to be equal in name & type (equal subsets can be chosen using the `tierNames` argument of the function). For example, if all `.TextGrid` files contain the tiers `Syl: IntervalTier`, `Phonetic: IntervalTier` and `Tone: TextTier` the conversion will work. However, if a single `.TextGrid` of the collection has the additional tier `Word: IntervalTier` the conversion will fail, although it can be made to work by specifying the equal subset `equalSubset = c('Syl', 'Phonetic', 'Tone')` and passing it into the function argument `convert_TextGridCollection_to_emuDB(..., tierNames = equalSubset, ...)`. 

```{r results='hide', message=FALSE, warning=FALSE}
# get the path to a folder containing .wav & .TextGrid files that is part of the demo data
path2folder = file.path(tempdir(), "emuR_demoData", "TextGrid_collection")

# convert this TextGridCollection to the emuDB format
convert_TextGridCollection_to_emuDB(path2folder, dbName = "myTGcolDB", 
                                    targetDir = tempdir())
```

This will create a new `emuDB` in the folder `tempdir()` called 'myTGcolDB'. The `emuDB` will contain all the tier information from the `.TextGrid` files but will not contain hierarchical information as `.TextGrid` files do not contain any linking information. If you are interested int how to programmatically generate links between the generated `SEGMENTS` and `EVENTS` see the Autobuilding section of the `emuDB` vignette.

```{r}
# remove the newly generated emuDB as we will not be needing it 
# throughout the rest of this vignette
unlink(file.path(tempdir(), "myTGcolDB"), recursive = T)
```


## BPF collections

Similar to the `convert_TextGridCollection_to_emuDB()` function the `emuR` package also provides a function for converting file collection consisting of BAS Partitur Format (BPF) and `.wav` files to the `emuDB` format.

```{r}
# get the path to a folder containing .wav & .par files that is part of the demo data
path2folder = file.path(tempdir(), "emuR_demoData", "BPF_collection")

# convert this BPFCollection to the emuDB format
convert_BPFCollection_to_emuDB(path2folder, dbName = 'myBPF-DB', 
                               targetDir = tempdir(), verbose = F)
```

As the BPF format also permits annotational units to be linked to one another, this conversion function can optionaly preserve this hierachical information by specifying the `refLevel` argument.

```{r}
# remove the newly generated emuDB as we will not be needing it 
# throughout the rest of this vignette
unlink(file.path(tempdir(), "myBPF-DB"), recursive = T)
```


# Loading and inspecting the database

As was mentioned in the introduction, the initial step to working with an `emuDB` is to load it into your current R session:

```{r}
# get the path to emuDB called 'ae' that is part of the demo data
path2folder = file.path(tempdir(), "emuR_demoData", "ae")

# load emuDB into current R session
ae = load_emuDB(path2folder, verbose = FALSE)
```

## Overview

Now that we have loaded the 'ae' `emuDB` into our R session let us get a first impression of what the 'ae' `emuDB` looks like
by calling:

```{r}
summary_emuDB(ae)
```

As you can see this command displays a lot of information. Most of the information is about the level and link definitions of the `emuDB`. 
The summary information about the level definitions shows for instance that the 'ae' database has a 'Word' level (that most likely contains 
word labels), which is of type 'ITEM' and therefore does not contain any time information. It also shows that a 'Phonetic' level (that most likely 
contains phonetic symbols) of type 'SEGMENT' is present, which means that each phonetic annotational unit carries start time and segment duration
information.

The summary information about the Link definitions shows, among others, these three 'Link definitions':

```
Word    ->      Syllable        ONE_TO_MANY 
Syllable        ->      Phoneme ONE_TO_MANY 
Phoneme ->      Phonetic        MANY_TO_MANY
```

This implicates annoational units from the 'Word' level can somehow be connected to units from the 'Phonetic' level via 
two other levels called 'Syllable' and 'Phoneme'. This is indeed the case and also the reason `emuR` is able to 
deduce the time information for annotational units without time information (`type: 'ITEM'`) if they are connected, 
even over multiple other levels, to annotational units with time information (`type: 'SEGMENT'`, `type: 'EVENT`).


The easiest way to think of levels and links is a graph for each recording where levels are different 
linguistic representations and the Links are the relations between them. Hence for our 'ae' `emuDB` we could say:
Each recording has words, syllables and phones, and the relations are: 
words consist of syllables, and syllables in turn consists of abstract phonemes, 
which are produced as certain phones. An schematic excerpt of such an annotation can be seen below:

![Alt text](pics/msajc003.svg)

## Database annotation / visual inspection

The EMU\_SDMS has a fairly unique approach to the database annotation and the visual inspection of the database, as it 
utilizes a web application called the EMU-webApp to act as it's graphical user interface. To be
able to transfer the necessary data to the web application let us now serve the `emuDB` to it by using the `serve()` function:

```{r eval=FALSE}
serve(ae)
```

Executing this command will block your R console and show you the following message:

```
Navigate your browser to the EMU-webApp URL: http://ips-lmu.github.io/EMU-webApp/
Server connection URL: ws://localhost:17890
To stop the server press EMU-webApp 'clear' button or reload the page in your browser.
```

By navigating to the above URL and clicking `connect` in the top menu bar and `connect` on the subsequent popup window, the EMU-webApp and 
your current R session are able to connect to each other. You can now use the EMU-webApp to visually inspect your `emuDB`, annotate your data and more.
Once you are finished using the EMU-webApp simply click the clear button in the top menu bar and your R console will free up again.

**INFO: For more information about how to use the EMU-webApp click the EMU-webApp icon in the top right hand corner in the webApps top menu bar. For more 
information about how to configure the EMU-webApp see the 'Configuring the EMU-webApp' section of the `emuDB` vignette.**

# Use cases

As we have already completed the first two steps described in the typical work-flow example in the introduction, we will now describe the the rest of the 
work-flow by walking through a few use cases. The use cases will start by asking a question about the 'ae' database and will continue by walking
you through the process of answering these questions by using the the mechanics the `emuR` package provides.

## 1.) *What is the average length of all 'n' Phonetic SEGMENTs in the 'ae' emuDB?*

The first thing that we will need to do to answer this fairly simple question, is query the database for all 'n' SEGMENTs.
This can easily be achieved using the `query()` function:

```{r message=FALSE, warning=FALSE}
sl = query(ae, query = "Phonetic==n")
print(sl)
```

The second argument of the `query()` contains a string that represents an EMU Query Language Version 2 (EQL2) statement. For multiple examples and an overview of what type of queries you can produce in EQL2 please see the `EQL` vignette.

Let us now calculate the mean durations of these segments:

```{r}
# calculate durations
d = dur(sl)
# calculate mean
mean(d)
```

## 2.) *What does the F1/F2 distribution of all Phonetic SEGMENTs that contain the labels I,o:,u:,V or @ look like?*

Once again we will start by querying our annotation structure for the SEGMENTs we are interessted in:

```{r results='hide', message=FALSE, warning=FALSE}
# query emuDB
sl = query(ae, "Phonetic==I|o:|u:|V|@")
```

Now that we have extracted the neccesary SEGMENT information we can simply call:

```{r}
# get formant values for those SEGMENTs
td = get_trackdata(ae, sl,
                   onTheFlyFunctionName = "forest",
                   resultType = "emuRtrackdata",
                   verbos = FALSE)
```

In this example the `get_trackdata` function uses a formant estimation function called `forest` to calculate the formant values 
on-the-fly. This signal processing function is part of the `wrassp` package that is used by the `emuR` package to perform signal
processing duties as is the case with the above `get_trackdata` command.

**INFO: For more information about the wrassp package and it's available signal processing functions see the wrassp_intro vignette 
that is part of the `wrassp` package.**

If the resultType parameter is set to "emuRtrackdata" the `get_trackdata` function returns an object with the following classes:

```{r}
class(td)
```

As we are dealing with a `data.table`/`data.frame` we can now simply use a package like `ggplot2` to visualize our F1/F2 distribution:

```{r, fig.height = 5, fig.width = 5}
# load package
library(ggplot2)

# scatter plot F1 and F2 values using ggplot2
ggplot(td, aes(x=T2, y=T1, label=td$labels)) + 
  geom_text(aes(colour=factor(labels))) + 
  scale_y_reverse() + scale_x_reverse() + 
  labs(x = "F2(Hz)", y = "F1(Hz)") +
  guides(colour=FALSE)
```

## 3.) Do the sibilants in the 'ae' emuDB differ with respect to their 1st spectral moment?

To answer this question we first have to find out what the labels are available in the Phonetic level. 



# Further reading

In this vignette we tried to give you a quick practical overview of what it is like working with the emuR package that is part of the
EMU_SDMS. If you are new to the system we definitely also recommend that you read the `emuDB` and `EQL` vignettes that are part of the `emuR`
package. These will give more insight into the structure of / how you can interact with with `emuDB`s and what the EMU Query Language offers.
As the new EMU system has kept most of the concepts of the legacy EMU system in place it is definitely also worth looking at
Jonathan Harrington's Book *Phonetic Analysis of Speech Corpora* [@harrington:2010a] even though some things will be outdated.

# References